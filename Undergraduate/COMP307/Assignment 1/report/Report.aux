\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Nearest Neighbor Method}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Class Labels For Test Data}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Comparing K1 And K3}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Nearest Neighbor Classification Discussion}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}K-Fold Cross Validation}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Clustering Problem}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Decision Tree Learning}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Decision Tree Results}{3}}
\@writefile{toc}{\contentsline {paragraph}{Over full test data}{3}}
\@writefile{toc}{\contentsline {paragraph}{Over split test data}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Pruning Discussion}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Pruning Techniques}{3}}
\@writefile{toc}{\contentsline {paragraph}{Reduced error pruning}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Reducing Accuracy On Training Data}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Improving Accuracy On Testing Data}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Impurity Measure Discussion}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Perceptron Learning}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Perceptron Performance}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Data Discussion}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Appendix A (Nearest Neighbor Output)}{6}}
\gdef \LT@i {\LT@entry 
    {2}{70.80565pt}\LT@entry 
    {1}{69.36125pt}\LT@entry 
    {1}{66.72237pt}\LT@entry 
    {1}{68.6668pt}\LT@entry 
    {1}{66.02791pt}\LT@entry 
    {3}{80.68994pt}}
